{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_declaration import prepare_content, get_values, parse_declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_path = os.path.join('..', 'data', '2*.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "declarations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/201707172348227.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/GoogleDrive/My Drive/se_projects/kg_declarations/code/parse_declaration.py:72: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  return odf.dropna(axis=1).to_dict(orient='record')\n",
      "  5%|▌         | 1/19 [00:00<00:04,  3.68it/s]/Volumes/GoogleDrive/My Drive/se_projects/kg_declarations/code/parse_declaration.py:63: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  return res_df.dropna(axis=1).to_dict(orient='record')\n",
      " 16%|█▌        | 3/19 [00:00<00:02,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/2017071723484910.xlsx\n",
      "../data/2017071723500415.xlsx\n",
      "../data/201707172350173.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 5/19 [00:00<00:01,  8.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/2017071723502914.xlsx\n",
      "../data/201707172350406.xlsx\n",
      "../data/201707172350518.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 9/19 [00:00<00:01,  9.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/201707180057594.xlsx\n",
      "../data/2017071800582415.xlsx\n",
      "../data/2017072020044114.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 11/19 [00:01<00:00, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/201707180059406.xlsx\n",
      "../data/2017071801001413.xlsx\n",
      "../data/2017071801004710.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 15/19 [00:01<00:00, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/201707180101122.xlsx\n",
      "../data/201707180101408.xlsx\n",
      "../data/201707180102186.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 17/19 [00:01<00:00, 10.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/201707201632226.xlsx\n",
      "../data/201707201632345.xlsx\n",
      "../data/201707180200036.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:01<00:00, 10.76it/s]\n"
     ]
    }
   ],
   "source": [
    "for path in tqdm(glob(tables_path)):\n",
    "    print(path)\n",
    "    df = pd.read_excel(path, index_col=None)\n",
    "    \n",
    "    declarations.append(parse_declaration(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '31/_12/2016г.',\n",
       " 'deputy': {'income': ['997 146 с. -по месту основной работы',\n",
       "   '714 546 с.-пенсия'],\n",
       "  'other_estate': [],\n",
       "  'real_estate': [{'наименование': 'дом', 'площадь (кв.м)': 172}],\n",
       "  'spendeturs': []},\n",
       " 'relatives': {'income': [],\n",
       "  'other_estate': [{'наименование': 'лег/автомобиль ',\n",
       "    'сведения о транспортных средствах': 'Тойота Камри, 2015г. V=2494Б'}],\n",
       "  'real_estate': [{'наименование': 'квартира', 'площадь (кв.м)': 187}],\n",
       "  'spendeturs': []},\n",
       " 'Должность декларанта': 'Депутат',\n",
       " 'Наименование государственного/ муниципального органа': 'Жогорку Кенеш Кыргызской Республики',\n",
       " 'ФИО декларанта': 'Абдылдаев Мыктыбек Юсупович'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "declarations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"data\": declarations}\n",
    "\n",
    "with open('../data/all_declarations.json', 'w') as f:\n",
    "    json.dump(data, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Serialize ``obj`` as a JSON formatted stream to ``fp`` (a\n",
       "``.write()``-supporting file-like object).\n",
       "\n",
       "If ``skipkeys`` is true then ``dict`` keys that are not basic types\n",
       "(``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n",
       "instead of raising a ``TypeError``.\n",
       "\n",
       "If ``ensure_ascii`` is false, then the strings written to ``fp`` can\n",
       "contain non-ASCII characters if they appear in strings contained in\n",
       "``obj``. Otherwise, all such characters are escaped in JSON strings.\n",
       "\n",
       "If ``check_circular`` is false, then the circular reference check\n",
       "for container types will be skipped and a circular reference will\n",
       "result in an ``OverflowError`` (or worse).\n",
       "\n",
       "If ``allow_nan`` is false, then it will be a ``ValueError`` to\n",
       "serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``)\n",
       "in strict compliance of the JSON specification, instead of using the\n",
       "JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n",
       "\n",
       "If ``indent`` is a non-negative integer, then JSON array elements and\n",
       "object members will be pretty-printed with that indent level. An indent\n",
       "level of 0 will only insert newlines. ``None`` is the most compact\n",
       "representation.\n",
       "\n",
       "If specified, ``separators`` should be an ``(item_separator, key_separator)``\n",
       "tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n",
       "``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n",
       "you should specify ``(',', ':')`` to eliminate whitespace.\n",
       "\n",
       "``default(obj)`` is a function that should return a serializable version\n",
       "of obj or raise TypeError. The default simply raises TypeError.\n",
       "\n",
       "If *sort_keys* is true (default: ``False``), then the output of\n",
       "dictionaries will be sorted by key.\n",
       "\n",
       "To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n",
       "``.default()`` method to serialize additional types), specify it with\n",
       "the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/py36/lib/python3.6/json/__init__.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?json.dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
